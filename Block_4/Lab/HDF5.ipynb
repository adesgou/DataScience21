{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands on HDF5\n",
    "This brief lab session gives an overview over the basic usage of the HDF5 file format for Python applications.\n",
    "\n",
    "Work through the examples and try to change some of the settings...\n",
    "\n",
    "### Sources:\n",
    "* HDF5 documentation https://portal.hdfgroup.org/display/HDF5/HDF5\n",
    "* h5py API: http://docs.h5py.org/en/stable/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py #this is the HDF5 lib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "#create some random data\n",
    "matrix1 = np.random.random(size = (1000,1000))\n",
    "matrix2 = np.random.random(size = (10000,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# write it to the same file - in two different arrays\n",
    "with h5py.File('hdf5_data.h5', 'w') as hdf: #note the write mode 'w'\n",
    "    hdf.create_dataset('dataset1', data=matrix1)\n",
    "    hdf.create_dataset('dataset2', data=matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of datasets in this file: \n",
      " ['dataset1', 'dataset2']\n",
      "Shape of dataset1: \n",
      " (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "#opening, listing and reading files\n",
    "with h5py.File('hdf5_data.h5','r') as hdf:\n",
    "    ls = list(hdf.keys())\n",
    "    print('List of datasets in this file: \\n', ls)\n",
    "    data = hdf.get('dataset2') #here data is still some hdf5 object\n",
    "    dataset1 = np.array(data) #need to convert it into numpy\n",
    "    print('Shape of dataset1: \\n', dataset1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35298937, 0.19084537, 0.77813152, ..., 0.48492118, 0.9588813 ,\n",
       "        0.89156765],\n",
       "       [0.01259683, 0.80003331, 0.23631204, ..., 0.08398393, 0.12874762,\n",
       "        0.97716024],\n",
       "       [0.92925425, 0.78632283, 0.0049041 , ..., 0.23286537, 0.65432988,\n",
       "        0.43653635],\n",
       "       ...,\n",
       "       [0.50616616, 0.40203264, 0.98987614, ..., 0.34526477, 0.20184567,\n",
       "        0.82073561],\n",
       "       [0.66550208, 0.68291915, 0.46589767, ..., 0.88377011, 0.81268262,\n",
       "        0.52053982],\n",
       "       [0.6857731 , 0.24782241, 0.25591154, ..., 0.76727604, 0.77452165,\n",
       "        0.73217506]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = h5py.File('hdf5_data.h5', 'r')\n",
    "ls = list(f.keys())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset1', 'dataset2']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array Slicing\n",
    "HDF5 support fancy array slicing - so we do not read all data just to get a slice: http://docs.h5py.org/en/latest/high/dataset.html#fancy-indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07922088, 0.20793175, 0.5460555 , ..., 0.75673413, 0.97837682,\n",
       "        0.40633718],\n",
       "       [0.48687628, 0.79027152, 0.52919646, ..., 0.77822124, 0.41939217,\n",
       "        0.70902382],\n",
       "       [0.40467815, 0.44258099, 0.83715752, ..., 0.80002386, 0.23864185,\n",
       "        0.97292973],\n",
       "       ...,\n",
       "       [0.01935417, 0.32257056, 0.44610822, ..., 0.14527461, 0.5316757 ,\n",
       "        0.73758511],\n",
       "       [0.30711561, 0.16160028, 0.25174914, ..., 0.36860369, 0.25817175,\n",
       "        0.23681105],\n",
       "       [0.32005088, 0.75381222, 0.06145083, ..., 0.24929502, 0.41978205,\n",
       "        0.68106082]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = h5py.File('hdf5_data.h5', 'r')\n",
    "f['dataset1'][100:120,:] # this notation mostly follows numpy notation -> try different slices!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Groups\n",
    "We can organize data in groups, just like in file systems where we have files (here datasets) in folders (here groups) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = np.random.random(size = (1000,1000))\n",
    "matrix2 = np.random.random(size = (1000,1000))\n",
    "matrix3 = np.random.random(size = (1000,1000))\n",
    "matrix4 = np.random.random(size = (1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('hdf5_groups.h5', 'w') as hdf:\n",
    "    G1 = hdf.create_group('Group1')\n",
    "    G1.create_dataset('dataset1', data = matrix1)\n",
    "    G1.create_dataset('dataset4', data = matrix4)\n",
    " \n",
    "    G21 = hdf.create_group('Group2/SubGroup1')\n",
    "    G21.create_dataset('dataset3', data = matrix3)\n",
    "    \n",
    "    G22 = hdf.create_group('Group2/SubGroup2')\n",
    "    G22.create_dataset('dataset2', data = matrix2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Items in the base directory: [('Group1', <HDF5 group \"/Group1\" (2 members)>), ('Group2', <HDF5 group \"/Group2\" (2 members)>)]\n",
      "Items in Group2: [('SubGroup1', <HDF5 group \"/Group2/SubGroup1\" (1 members)>), ('SubGroup2', <HDF5 group \"/Group2/SubGroup2\" (1 members)>)]\n",
      "Items in Group21: [('dataset3', <HDF5 dataset \"dataset3\": shape (1000, 1000), type \"<f8\">)]\n",
      "(1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('hdf5_groups.h5','r') as hdf:\n",
    "    base_items = list(hdf.items())\n",
    "    print('Items in the base directory:', base_items)\n",
    "    G2 = hdf.get('Group2')\n",
    "    G2_items = list(G2.items())\n",
    "    print('Items in Group2:', G2_items)\n",
    "    G21 = G2.get('/Group2/SubGroup1')\n",
    "    G21_items = list(G21.items())\n",
    "    print('Items in Group21:', G21_items)\n",
    "    dataset3 = np.array(G21.get('dataset3'))\n",
    "    print(dataset3.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is happening? Interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress Data\n",
    "HDF5 also support native data compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = np.random.random(size = (1000,1000))\n",
    "matrix2 = np.random.random(size = (1000,1000))\n",
    "matrix3 = np.random.random(size = (1000,1000))\n",
    "matrix4 = np.random.random(size = (1000,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('hdf5_groups_compressed.h5', 'w') as hdf:\n",
    "    G1 = hdf.create_group('Group1')\n",
    "    G1.create_dataset('dataset1', data = matrix1, compression=\"gzip\", compression_opts=9)\n",
    "    G1.create_dataset('dataset4', data = matrix4, compression=\"gzip\", compression_opts=9)\n",
    " \n",
    "    G21 = hdf.create_group('Group2/SubGroup1')\n",
    "    G21.create_dataset('dataset3', data = matrix3, compression=\"gzip\", compression_opts=9)\n",
    "    \n",
    "    G22 = hdf.create_group('Group2/SubGroup2')\n",
    "    G22.create_dataset('dataset2', data = matrix2, compression=\"gzip\", compression_opts=9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attributes\n",
    "We can add meta information in form of attributes of files, groups and datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1 = np.random.random(size = (1000,1000))\n",
    "matrix2 = np.random.random(size = (10000,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the HDF5 file\n",
    "hdf = h5py.File('test.h5', 'w')\n",
    "\n",
    "# Create the datasets\n",
    "dataset1 = hdf.create_dataset('dataset1', data=matrix1)\n",
    "dataset2 = hdf.create_dataset('dataset2', data=matrix2)\n",
    "\n",
    "# Set attributes\n",
    "dataset1.attrs['CLASS'] = 'DATA MATRIX'\n",
    "dataset1.attrs['VERSION'] = '1.1'\n",
    "\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of datasets in this file: \n",
      " ['dataset1', 'dataset2']\n",
      "Shape of dataset1: \n",
      " (1000, 1000)\n",
      "CLASS\n",
      "DATA MATRIX\n",
      "DATA MATRIX\n"
     ]
    }
   ],
   "source": [
    "# Read the HDF5 file\n",
    "hdf = h5py.File('test.h5', 'r')\n",
    "ls = list(hdf.keys())\n",
    "print('List of datasets in this file: \\n', ls)\n",
    "data = hdf.get('dataset1')\n",
    "dataset1 = np.array(data)\n",
    "print('Shape of dataset1: \\n', dataset1.shape)\n",
    "#read the attributes\n",
    "k = list(data.attrs.keys())\n",
    "v = list(data.attrs.values())\n",
    "print(k[0])\n",
    "print(v[0])\n",
    "print(data.attrs[k[0]])\n",
    "\n",
    "hdf.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HDF5 and ***Pandas***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# creates (or opens in append mode) an hdf5 file\n",
    "hdf = pd.HDFStore('hdf5_pandas.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('../../DATA/FL_insurance_sample.csv')# put the dataset in the storage\n",
    "hdf.put('DF1', df1, format='table', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "         \"city\": [\"Tripoli\", \"Sydney\", \"Tripoli\", \"Rome\", \"Rome\", \"Tripoli\",\"Rome\", \"Sydney\", \"Sydney\"],\n",
    "         \"rank\": [\"1st\", \"2nd\", \"1st\", \"2nd\", \"1st\", \"2nd\",\"1st\", \"2nd\", \"1st\"], \n",
    "         \"score1\": [44, 48, 39, 41, 38, 44, 34, 54, 61],\n",
    "         \"score2\": [67, 63, 55, 70, 64, 77, 45, 66, 72]\n",
    "        }\n",
    "        \n",
    "df2 = pd.DataFrame(data, columns = ['city', 'rank','score1','score2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>rank</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tripoli</td>\n",
       "      <td>1st</td>\n",
       "      <td>44</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>2nd</td>\n",
       "      <td>48</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tripoli</td>\n",
       "      <td>1st</td>\n",
       "      <td>39</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rome</td>\n",
       "      <td>2nd</td>\n",
       "      <td>41</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rome</td>\n",
       "      <td>1st</td>\n",
       "      <td>38</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tripoli</td>\n",
       "      <td>2nd</td>\n",
       "      <td>44</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rome</td>\n",
       "      <td>1st</td>\n",
       "      <td>34</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>2nd</td>\n",
       "      <td>54</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sydney</td>\n",
       "      <td>1st</td>\n",
       "      <td>61</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city rank  score1  score2\n",
       "0  Tripoli  1st      44      67\n",
       "1   Sydney  2nd      48      63\n",
       "2  Tripoli  1st      39      55\n",
       "3     Rome  2nd      41      70\n",
       "4     Rome  1st      38      64\n",
       "5  Tripoli  2nd      44      77\n",
       "6     Rome  1st      34      45\n",
       "7   Sydney  2nd      54      66\n",
       "8   Sydney  1st      61      72"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hdf.put('DF2Key', df2,format='table', data_columns=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf.close() # close the hdf5 file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# open hdf5 file for reading\n",
    "hdf = pd.HDFStore('hdf5_pandas.h5',mode='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/DF1', '/DF2Key']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hdf.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df1 = hdf.get('/DF1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>policyID</th>\n",
       "      <th>statecode</th>\n",
       "      <th>county</th>\n",
       "      <th>eq_site_limit</th>\n",
       "      <th>hu_site_limit</th>\n",
       "      <th>fl_site_limit</th>\n",
       "      <th>fr_site_limit</th>\n",
       "      <th>tiv_2011</th>\n",
       "      <th>tiv_2012</th>\n",
       "      <th>eq_site_deductible</th>\n",
       "      <th>hu_site_deductible</th>\n",
       "      <th>fl_site_deductible</th>\n",
       "      <th>fr_site_deductible</th>\n",
       "      <th>point_latitude</th>\n",
       "      <th>point_longitude</th>\n",
       "      <th>line</th>\n",
       "      <th>construction</th>\n",
       "      <th>point_granularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119736</td>\n",
       "      <td>FL</td>\n",
       "      <td>CLAY COUNTY</td>\n",
       "      <td>498960.0</td>\n",
       "      <td>498960.00</td>\n",
       "      <td>498960.0</td>\n",
       "      <td>498960.0</td>\n",
       "      <td>498960.00</td>\n",
       "      <td>792148.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9979.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.102261</td>\n",
       "      <td>-81.711777</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Masonry</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>448094</td>\n",
       "      <td>FL</td>\n",
       "      <td>CLAY COUNTY</td>\n",
       "      <td>1322376.3</td>\n",
       "      <td>1322376.30</td>\n",
       "      <td>1322376.3</td>\n",
       "      <td>1322376.3</td>\n",
       "      <td>1322376.30</td>\n",
       "      <td>1438163.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.063936</td>\n",
       "      <td>-81.707664</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Masonry</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206893</td>\n",
       "      <td>FL</td>\n",
       "      <td>CLAY COUNTY</td>\n",
       "      <td>190724.4</td>\n",
       "      <td>190724.40</td>\n",
       "      <td>190724.4</td>\n",
       "      <td>190724.4</td>\n",
       "      <td>190724.40</td>\n",
       "      <td>192476.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.089579</td>\n",
       "      <td>-81.700455</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Wood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>333743</td>\n",
       "      <td>FL</td>\n",
       "      <td>CLAY COUNTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79520.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79520.76</td>\n",
       "      <td>86854.48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.063236</td>\n",
       "      <td>-81.707703</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Wood</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172534</td>\n",
       "      <td>FL</td>\n",
       "      <td>CLAY COUNTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254281.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>254281.5</td>\n",
       "      <td>254281.50</td>\n",
       "      <td>246144.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.060614</td>\n",
       "      <td>-81.702675</td>\n",
       "      <td>Residential</td>\n",
       "      <td>Wood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   policyID statecode       county  eq_site_limit  hu_site_limit  \\\n",
       "0    119736        FL  CLAY COUNTY       498960.0      498960.00   \n",
       "1    448094        FL  CLAY COUNTY      1322376.3     1322376.30   \n",
       "2    206893        FL  CLAY COUNTY       190724.4      190724.40   \n",
       "3    333743        FL  CLAY COUNTY            0.0       79520.76   \n",
       "4    172534        FL  CLAY COUNTY            0.0      254281.50   \n",
       "\n",
       "   fl_site_limit  fr_site_limit    tiv_2011    tiv_2012  eq_site_deductible  \\\n",
       "0       498960.0       498960.0   498960.00   792148.90                 0.0   \n",
       "1      1322376.3      1322376.3  1322376.30  1438163.57                 0.0   \n",
       "2       190724.4       190724.4   190724.40   192476.78                 0.0   \n",
       "3            0.0            0.0    79520.76    86854.48                 0.0   \n",
       "4            0.0       254281.5   254281.50   246144.49                 0.0   \n",
       "\n",
       "   hu_site_deductible  fl_site_deductible  fr_site_deductible  point_latitude  \\\n",
       "0              9979.2                 0.0                   0       30.102261   \n",
       "1                 0.0                 0.0                   0       30.063936   \n",
       "2                 0.0                 0.0                   0       30.089579   \n",
       "3                 0.0                 0.0                   0       30.063236   \n",
       "4                 0.0                 0.0                   0       30.060614   \n",
       "\n",
       "   point_longitude         line construction  point_granularity  \n",
       "0       -81.711777  Residential      Masonry                  1  \n",
       "1       -81.707664  Residential      Masonry                  3  \n",
       "2       -81.700455  Residential         Wood                  1  \n",
       "3       -81.707703  Residential         Wood                  3  \n",
       "4       -81.702675  Residential         Wood                  1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "hdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
